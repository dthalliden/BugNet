{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bugNet.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHgC6yPDjUOe"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWENIlaisJ5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e389f79-f1b9-4c4a-d197-8e68e6a33299"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDlrcIAXjZEA",
        "outputId": "bac11d4e-9282-495e-be06-5de343e9b0d8"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/Bugs.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n",
        "\n",
        "dataGenerator = keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3, samplewise_center = True)\n",
        "\n",
        "test = dataGenerator.flow_from_directory(\"/tmp/Bugs\", class_mode='categorical', target_size = (64,64), batch_size=32, subset=\"validation\", shuffle=True)\n",
        "train = dataGenerator.flow_from_directory(\"/tmp/Bugs\", class_mode='categorical', target_size = (64,64), batch_size=32, subset=\"training\", shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 227 images belonging to 3 classes.\n",
            "Found 537 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJOn28rqjzp3",
        "outputId": "c6f886a0-3e19-48b4-eb39-711e7625472f"
      },
      "source": [
        "def bugNet():\n",
        "  \n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomRotation(1,input_shape = (64,64,3)))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomFlip(\"vertical\"))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomZoom(0.2))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomTranslation(height_factor = 0.1, width_factor = 0.1))\n",
        "    model.add(ResNet50V2(include_top = False, weights = \"imagenet\", input_tensor = keras.Input(shape = (64, 64, 3))))\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
        "    \n",
        "    #iterationsToChangeAt = [60,120]\n",
        "    #LRs = [.001, .0001, 0.00001]\n",
        "    #stepRate = keras.optimizers.schedules.PiecewiseConstantDecay(iterationsToChangeAt, LRs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate = 0.001), metrics=[\"categorical_accuracy\"])\n",
        "    \n",
        "    return(model)\n",
        "    \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "model = bugNet()\n",
        "model.summary()\n",
        "model.fit(train, epochs=150, validation_data=test, callbacks=[mcp_save, reduce_lr_loss])\n",
        "\n",
        "#IMPORTANT: Your model must be saved as \"Q3.h5\"\n",
        "model.save(\"./Q2.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_rotation (RandomRotat (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_flip (RandomFlip)     (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_flip_1 (RandomFlip)   (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_zoom (RandomZoom)     (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_translation (RandomTr (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 2, 2, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 24,090,115\n",
            "Trainable params: 24,044,675\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            " 1/17 [>.............................] - ETA: 5:12 - loss: 2.0804 - categorical_accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - ETA: 0s - loss: 1.8771 - categorical_accuracy: 0.3285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/17 [==============================] - 39s 1s/step - loss: 1.8716 - categorical_accuracy: 0.3288 - val_loss: 7.8149 - val_categorical_accuracy: 0.3084\n",
            "Epoch 2/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.5647 - categorical_accuracy: 0.3504 - val_loss: 3.5289 - val_categorical_accuracy: 0.3348\n",
            "Epoch 3/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.3126 - categorical_accuracy: 0.3414 - val_loss: 2.0954 - val_categorical_accuracy: 0.3965\n",
            "Epoch 4/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.1439 - categorical_accuracy: 0.4435 - val_loss: 1.5529 - val_categorical_accuracy: 0.4229\n",
            "Epoch 5/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0887 - categorical_accuracy: 0.4085 - val_loss: 1.3579 - val_categorical_accuracy: 0.4185\n",
            "Epoch 6/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.1163 - categorical_accuracy: 0.4238 - val_loss: 1.2239 - val_categorical_accuracy: 0.4317\n",
            "Epoch 7/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.1068 - categorical_accuracy: 0.4076 - val_loss: 1.1288 - val_categorical_accuracy: 0.4449\n",
            "Epoch 8/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0828 - categorical_accuracy: 0.4213 - val_loss: 1.0800 - val_categorical_accuracy: 0.4317\n",
            "Epoch 9/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0720 - categorical_accuracy: 0.4335 - val_loss: 1.0660 - val_categorical_accuracy: 0.4449\n",
            "Epoch 10/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0416 - categorical_accuracy: 0.4807 - val_loss: 1.0352 - val_categorical_accuracy: 0.4273\n",
            "Epoch 11/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0226 - categorical_accuracy: 0.4368 - val_loss: 1.0084 - val_categorical_accuracy: 0.4537\n",
            "Epoch 12/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0629 - categorical_accuracy: 0.4698 - val_loss: 0.9968 - val_categorical_accuracy: 0.4890\n",
            "Epoch 13/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0343 - categorical_accuracy: 0.5103 - val_loss: 0.9753 - val_categorical_accuracy: 0.4890\n",
            "Epoch 14/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9658 - categorical_accuracy: 0.4964 - val_loss: 0.9588 - val_categorical_accuracy: 0.5066\n",
            "Epoch 15/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9749 - categorical_accuracy: 0.5171 - val_loss: 0.9319 - val_categorical_accuracy: 0.5286\n",
            "Epoch 16/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 1.0067 - categorical_accuracy: 0.5521 - val_loss: 0.9116 - val_categorical_accuracy: 0.5727\n",
            "Epoch 17/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9559 - categorical_accuracy: 0.5249 - val_loss: 0.8825 - val_categorical_accuracy: 0.5595\n",
            "Epoch 18/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9135 - categorical_accuracy: 0.5731 - val_loss: 0.8796 - val_categorical_accuracy: 0.5639\n",
            "Epoch 19/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9223 - categorical_accuracy: 0.5595 - val_loss: 0.8671 - val_categorical_accuracy: 0.5771\n",
            "Epoch 20/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8909 - categorical_accuracy: 0.5994 - val_loss: 0.8539 - val_categorical_accuracy: 0.6035\n",
            "Epoch 21/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8742 - categorical_accuracy: 0.6176 - val_loss: 0.8505 - val_categorical_accuracy: 0.6123\n",
            "Epoch 22/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.9027 - categorical_accuracy: 0.5865 - val_loss: 0.8327 - val_categorical_accuracy: 0.6344\n",
            "Epoch 23/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8531 - categorical_accuracy: 0.6125 - val_loss: 0.8315 - val_categorical_accuracy: 0.6300\n",
            "Epoch 24/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8679 - categorical_accuracy: 0.6498 - val_loss: 0.8052 - val_categorical_accuracy: 0.6476\n",
            "Epoch 25/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8552 - categorical_accuracy: 0.5991 - val_loss: 0.7960 - val_categorical_accuracy: 0.6520\n",
            "Epoch 26/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8665 - categorical_accuracy: 0.6068 - val_loss: 0.7954 - val_categorical_accuracy: 0.6476\n",
            "Epoch 27/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8193 - categorical_accuracy: 0.6557 - val_loss: 0.7866 - val_categorical_accuracy: 0.6520\n",
            "Epoch 28/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8276 - categorical_accuracy: 0.6304 - val_loss: 0.7881 - val_categorical_accuracy: 0.6564\n",
            "Epoch 29/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7670 - categorical_accuracy: 0.6547 - val_loss: 0.7737 - val_categorical_accuracy: 0.6608\n",
            "Epoch 30/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8161 - categorical_accuracy: 0.6466 - val_loss: 0.7755 - val_categorical_accuracy: 0.6652\n",
            "Epoch 31/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.8034 - categorical_accuracy: 0.6596 - val_loss: 0.7724 - val_categorical_accuracy: 0.6740\n",
            "Epoch 32/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7690 - categorical_accuracy: 0.6633 - val_loss: 0.7664 - val_categorical_accuracy: 0.6740\n",
            "Epoch 33/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7693 - categorical_accuracy: 0.7071 - val_loss: 0.7659 - val_categorical_accuracy: 0.6784\n",
            "Epoch 34/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7275 - categorical_accuracy: 0.6647 - val_loss: 0.7532 - val_categorical_accuracy: 0.6784\n",
            "Epoch 35/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7459 - categorical_accuracy: 0.6559 - val_loss: 0.7528 - val_categorical_accuracy: 0.6960\n",
            "Epoch 36/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6713 - categorical_accuracy: 0.7296 - val_loss: 0.7386 - val_categorical_accuracy: 0.6960\n",
            "Epoch 37/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7395 - categorical_accuracy: 0.7181 - val_loss: 0.7351 - val_categorical_accuracy: 0.7048\n",
            "Epoch 38/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7509 - categorical_accuracy: 0.6604 - val_loss: 0.7307 - val_categorical_accuracy: 0.6960\n",
            "Epoch 39/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7488 - categorical_accuracy: 0.6530 - val_loss: 0.7233 - val_categorical_accuracy: 0.6872\n",
            "Epoch 40/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6757 - categorical_accuracy: 0.7375 - val_loss: 0.7106 - val_categorical_accuracy: 0.6872\n",
            "Epoch 41/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7193 - categorical_accuracy: 0.6718 - val_loss: 0.7129 - val_categorical_accuracy: 0.6960\n",
            "Epoch 42/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7103 - categorical_accuracy: 0.6695 - val_loss: 0.7037 - val_categorical_accuracy: 0.6960\n",
            "Epoch 43/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.7269 - categorical_accuracy: 0.6528 - val_loss: 0.7088 - val_categorical_accuracy: 0.7004\n",
            "Epoch 44/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6551 - categorical_accuracy: 0.7100 - val_loss: 0.7041 - val_categorical_accuracy: 0.7004\n",
            "Epoch 45/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6769 - categorical_accuracy: 0.7175 - val_loss: 0.6913 - val_categorical_accuracy: 0.7048\n",
            "Epoch 46/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6039 - categorical_accuracy: 0.7339 - val_loss: 0.6705 - val_categorical_accuracy: 0.7004\n",
            "Epoch 47/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6091 - categorical_accuracy: 0.7435 - val_loss: 0.6716 - val_categorical_accuracy: 0.7048\n",
            "Epoch 48/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6039 - categorical_accuracy: 0.7556 - val_loss: 0.6749 - val_categorical_accuracy: 0.7357\n",
            "Epoch 49/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5975 - categorical_accuracy: 0.7757 - val_loss: 0.6640 - val_categorical_accuracy: 0.7357\n",
            "Epoch 50/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5718 - categorical_accuracy: 0.7956 - val_loss: 0.6739 - val_categorical_accuracy: 0.7401\n",
            "Epoch 51/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.6290 - categorical_accuracy: 0.7475 - val_loss: 0.6679 - val_categorical_accuracy: 0.7401\n",
            "Epoch 52/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5734 - categorical_accuracy: 0.7680 - val_loss: 0.6741 - val_categorical_accuracy: 0.7577\n",
            "Epoch 53/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5558 - categorical_accuracy: 0.7739 - val_loss: 0.6650 - val_categorical_accuracy: 0.7445\n",
            "Epoch 54/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5707 - categorical_accuracy: 0.7748 - val_loss: 0.6598 - val_categorical_accuracy: 0.7577\n",
            "Epoch 55/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5525 - categorical_accuracy: 0.7756 - val_loss: 0.6491 - val_categorical_accuracy: 0.7665\n",
            "Epoch 56/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5293 - categorical_accuracy: 0.7922 - val_loss: 0.6570 - val_categorical_accuracy: 0.7533\n",
            "Epoch 57/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5679 - categorical_accuracy: 0.7948 - val_loss: 0.6428 - val_categorical_accuracy: 0.7533\n",
            "Epoch 58/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5793 - categorical_accuracy: 0.7743 - val_loss: 0.6288 - val_categorical_accuracy: 0.7665\n",
            "Epoch 59/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5141 - categorical_accuracy: 0.7988 - val_loss: 0.6217 - val_categorical_accuracy: 0.7709\n",
            "Epoch 60/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4803 - categorical_accuracy: 0.8170 - val_loss: 0.6194 - val_categorical_accuracy: 0.7709\n",
            "Epoch 61/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5590 - categorical_accuracy: 0.7751 - val_loss: 0.6230 - val_categorical_accuracy: 0.7709\n",
            "Epoch 62/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5358 - categorical_accuracy: 0.7939 - val_loss: 0.6184 - val_categorical_accuracy: 0.7621\n",
            "Epoch 63/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5449 - categorical_accuracy: 0.7693 - val_loss: 0.6124 - val_categorical_accuracy: 0.7665\n",
            "Epoch 64/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5047 - categorical_accuracy: 0.8110 - val_loss: 0.6125 - val_categorical_accuracy: 0.7753\n",
            "Epoch 65/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4673 - categorical_accuracy: 0.8299 - val_loss: 0.6150 - val_categorical_accuracy: 0.7709\n",
            "Epoch 66/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4730 - categorical_accuracy: 0.8201 - val_loss: 0.6131 - val_categorical_accuracy: 0.7621\n",
            "Epoch 67/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4511 - categorical_accuracy: 0.8219 - val_loss: 0.6153 - val_categorical_accuracy: 0.7709\n",
            "Epoch 68/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.5119 - categorical_accuracy: 0.7699 - val_loss: 0.6136 - val_categorical_accuracy: 0.7533\n",
            "Epoch 69/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4784 - categorical_accuracy: 0.8140 - val_loss: 0.6214 - val_categorical_accuracy: 0.7533\n",
            "Epoch 70/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4365 - categorical_accuracy: 0.8277 - val_loss: 0.6206 - val_categorical_accuracy: 0.7621\n",
            "Epoch 71/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4721 - categorical_accuracy: 0.8203 - val_loss: 0.6161 - val_categorical_accuracy: 0.7577\n",
            "Epoch 72/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4232 - categorical_accuracy: 0.8272 - val_loss: 0.6190 - val_categorical_accuracy: 0.7621\n",
            "Epoch 73/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4670 - categorical_accuracy: 0.8139 - val_loss: 0.6192 - val_categorical_accuracy: 0.7533\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 74/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4103 - categorical_accuracy: 0.8654 - val_loss: 0.6127 - val_categorical_accuracy: 0.7577\n",
            "Epoch 75/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4071 - categorical_accuracy: 0.8472 - val_loss: 0.6105 - val_categorical_accuracy: 0.7621\n",
            "Epoch 76/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4782 - categorical_accuracy: 0.8341 - val_loss: 0.6066 - val_categorical_accuracy: 0.7665\n",
            "Epoch 77/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4458 - categorical_accuracy: 0.8308 - val_loss: 0.6047 - val_categorical_accuracy: 0.7665\n",
            "Epoch 78/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4887 - categorical_accuracy: 0.7989 - val_loss: 0.6068 - val_categorical_accuracy: 0.7665\n",
            "Epoch 79/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4310 - categorical_accuracy: 0.8350 - val_loss: 0.6065 - val_categorical_accuracy: 0.7665\n",
            "Epoch 80/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4678 - categorical_accuracy: 0.8243 - val_loss: 0.6040 - val_categorical_accuracy: 0.7665\n",
            "Epoch 81/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4446 - categorical_accuracy: 0.8193 - val_loss: 0.6005 - val_categorical_accuracy: 0.7665\n",
            "Epoch 82/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4586 - categorical_accuracy: 0.8171 - val_loss: 0.5980 - val_categorical_accuracy: 0.7665\n",
            "Epoch 83/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3858 - categorical_accuracy: 0.8661 - val_loss: 0.5963 - val_categorical_accuracy: 0.7665\n",
            "Epoch 84/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4632 - categorical_accuracy: 0.8229 - val_loss: 0.5947 - val_categorical_accuracy: 0.7665\n",
            "Epoch 85/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4041 - categorical_accuracy: 0.8526 - val_loss: 0.5948 - val_categorical_accuracy: 0.7709\n",
            "Epoch 86/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4672 - categorical_accuracy: 0.7990 - val_loss: 0.5935 - val_categorical_accuracy: 0.7709\n",
            "Epoch 87/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4334 - categorical_accuracy: 0.8207 - val_loss: 0.5920 - val_categorical_accuracy: 0.7753\n",
            "Epoch 88/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4418 - categorical_accuracy: 0.8324 - val_loss: 0.5909 - val_categorical_accuracy: 0.7797\n",
            "Epoch 89/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4573 - categorical_accuracy: 0.8259 - val_loss: 0.5895 - val_categorical_accuracy: 0.7797\n",
            "Epoch 90/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4913 - categorical_accuracy: 0.7999 - val_loss: 0.5889 - val_categorical_accuracy: 0.7753\n",
            "Epoch 91/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4257 - categorical_accuracy: 0.8162 - val_loss: 0.5902 - val_categorical_accuracy: 0.7709\n",
            "Epoch 92/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4571 - categorical_accuracy: 0.8083 - val_loss: 0.5876 - val_categorical_accuracy: 0.7797\n",
            "Epoch 93/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4388 - categorical_accuracy: 0.8150 - val_loss: 0.5896 - val_categorical_accuracy: 0.7797\n",
            "Epoch 94/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4387 - categorical_accuracy: 0.8070 - val_loss: 0.5894 - val_categorical_accuracy: 0.7753\n",
            "Epoch 95/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4724 - categorical_accuracy: 0.8146 - val_loss: 0.5879 - val_categorical_accuracy: 0.7753\n",
            "Epoch 96/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4584 - categorical_accuracy: 0.8408 - val_loss: 0.5868 - val_categorical_accuracy: 0.7797\n",
            "Epoch 97/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4563 - categorical_accuracy: 0.8156 - val_loss: 0.5866 - val_categorical_accuracy: 0.7665\n",
            "Epoch 98/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3683 - categorical_accuracy: 0.8555 - val_loss: 0.5851 - val_categorical_accuracy: 0.7709\n",
            "Epoch 99/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4418 - categorical_accuracy: 0.8256 - val_loss: 0.5847 - val_categorical_accuracy: 0.7709\n",
            "Epoch 100/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4328 - categorical_accuracy: 0.8076 - val_loss: 0.5842 - val_categorical_accuracy: 0.7621\n",
            "Epoch 101/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3959 - categorical_accuracy: 0.8586 - val_loss: 0.5823 - val_categorical_accuracy: 0.7709\n",
            "Epoch 102/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3851 - categorical_accuracy: 0.8625 - val_loss: 0.5805 - val_categorical_accuracy: 0.7709\n",
            "Epoch 103/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4758 - categorical_accuracy: 0.8099 - val_loss: 0.5822 - val_categorical_accuracy: 0.7753\n",
            "Epoch 104/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4369 - categorical_accuracy: 0.8387 - val_loss: 0.5798 - val_categorical_accuracy: 0.7753\n",
            "Epoch 105/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3786 - categorical_accuracy: 0.8619 - val_loss: 0.5798 - val_categorical_accuracy: 0.7709\n",
            "Epoch 106/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4850 - categorical_accuracy: 0.7903 - val_loss: 0.5832 - val_categorical_accuracy: 0.7709\n",
            "Epoch 107/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3947 - categorical_accuracy: 0.8524 - val_loss: 0.5840 - val_categorical_accuracy: 0.7753\n",
            "Epoch 108/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4629 - categorical_accuracy: 0.8181 - val_loss: 0.5818 - val_categorical_accuracy: 0.7797\n",
            "Epoch 109/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4015 - categorical_accuracy: 0.8579 - val_loss: 0.5808 - val_categorical_accuracy: 0.7797\n",
            "Epoch 110/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4699 - categorical_accuracy: 0.8316 - val_loss: 0.5786 - val_categorical_accuracy: 0.7841\n",
            "Epoch 111/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4262 - categorical_accuracy: 0.8468 - val_loss: 0.5792 - val_categorical_accuracy: 0.7797\n",
            "Epoch 112/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4306 - categorical_accuracy: 0.8479 - val_loss: 0.5785 - val_categorical_accuracy: 0.7841\n",
            "Epoch 113/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4597 - categorical_accuracy: 0.8241 - val_loss: 0.5791 - val_categorical_accuracy: 0.7797\n",
            "Epoch 114/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4416 - categorical_accuracy: 0.8167 - val_loss: 0.5792 - val_categorical_accuracy: 0.7753\n",
            "Epoch 115/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4471 - categorical_accuracy: 0.8303 - val_loss: 0.5791 - val_categorical_accuracy: 0.7753\n",
            "Epoch 116/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4383 - categorical_accuracy: 0.8382 - val_loss: 0.5796 - val_categorical_accuracy: 0.7753\n",
            "Epoch 117/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3828 - categorical_accuracy: 0.8534 - val_loss: 0.5804 - val_categorical_accuracy: 0.7665\n",
            "Epoch 118/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3933 - categorical_accuracy: 0.8581 - val_loss: 0.5806 - val_categorical_accuracy: 0.7709\n",
            "Epoch 119/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4535 - categorical_accuracy: 0.8335 - val_loss: 0.5818 - val_categorical_accuracy: 0.7709\n",
            "Epoch 120/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3990 - categorical_accuracy: 0.8549 - val_loss: 0.5809 - val_categorical_accuracy: 0.7665\n",
            "Epoch 121/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4147 - categorical_accuracy: 0.8597 - val_loss: 0.5808 - val_categorical_accuracy: 0.7709\n",
            "Epoch 122/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4219 - categorical_accuracy: 0.8442 - val_loss: 0.5837 - val_categorical_accuracy: 0.7709\n",
            "\n",
            "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 123/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4325 - categorical_accuracy: 0.8105 - val_loss: 0.5828 - val_categorical_accuracy: 0.7621\n",
            "Epoch 124/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4001 - categorical_accuracy: 0.8537 - val_loss: 0.5836 - val_categorical_accuracy: 0.7621\n",
            "Epoch 125/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4390 - categorical_accuracy: 0.8430 - val_loss: 0.5839 - val_categorical_accuracy: 0.7621\n",
            "Epoch 126/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4494 - categorical_accuracy: 0.8190 - val_loss: 0.5838 - val_categorical_accuracy: 0.7621\n",
            "Epoch 127/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4589 - categorical_accuracy: 0.8002 - val_loss: 0.5842 - val_categorical_accuracy: 0.7621\n",
            "Epoch 128/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4221 - categorical_accuracy: 0.8205 - val_loss: 0.5863 - val_categorical_accuracy: 0.7665\n",
            "Epoch 129/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4298 - categorical_accuracy: 0.8216 - val_loss: 0.5836 - val_categorical_accuracy: 0.7665\n",
            "Epoch 130/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4778 - categorical_accuracy: 0.8109 - val_loss: 0.5854 - val_categorical_accuracy: 0.7621\n",
            "Epoch 131/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4239 - categorical_accuracy: 0.8464 - val_loss: 0.5845 - val_categorical_accuracy: 0.7665\n",
            "Epoch 132/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4502 - categorical_accuracy: 0.8326 - val_loss: 0.5852 - val_categorical_accuracy: 0.7709\n",
            "\n",
            "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 133/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4321 - categorical_accuracy: 0.8526 - val_loss: 0.5878 - val_categorical_accuracy: 0.7665\n",
            "Epoch 134/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4679 - categorical_accuracy: 0.8117 - val_loss: 0.5878 - val_categorical_accuracy: 0.7709\n",
            "Epoch 135/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4224 - categorical_accuracy: 0.8337 - val_loss: 0.5869 - val_categorical_accuracy: 0.7665\n",
            "Epoch 136/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4136 - categorical_accuracy: 0.8381 - val_loss: 0.5888 - val_categorical_accuracy: 0.7621\n",
            "Epoch 137/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4477 - categorical_accuracy: 0.8250 - val_loss: 0.5885 - val_categorical_accuracy: 0.7621\n",
            "Epoch 138/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3722 - categorical_accuracy: 0.8584 - val_loss: 0.5848 - val_categorical_accuracy: 0.7621\n",
            "Epoch 139/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4979 - categorical_accuracy: 0.8152 - val_loss: 0.5865 - val_categorical_accuracy: 0.7665\n",
            "Epoch 140/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4420 - categorical_accuracy: 0.8095 - val_loss: 0.5880 - val_categorical_accuracy: 0.7709\n",
            "Epoch 141/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4295 - categorical_accuracy: 0.8390 - val_loss: 0.5907 - val_categorical_accuracy: 0.7665\n",
            "Epoch 142/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4476 - categorical_accuracy: 0.8274 - val_loss: 0.5920 - val_categorical_accuracy: 0.7665\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 143/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4044 - categorical_accuracy: 0.8635 - val_loss: 0.5909 - val_categorical_accuracy: 0.7753\n",
            "Epoch 144/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4485 - categorical_accuracy: 0.8201 - val_loss: 0.5890 - val_categorical_accuracy: 0.7797\n",
            "Epoch 145/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4141 - categorical_accuracy: 0.8166 - val_loss: 0.5861 - val_categorical_accuracy: 0.7841\n",
            "Epoch 146/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4322 - categorical_accuracy: 0.8369 - val_loss: 0.5869 - val_categorical_accuracy: 0.7753\n",
            "Epoch 147/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3701 - categorical_accuracy: 0.8599 - val_loss: 0.5845 - val_categorical_accuracy: 0.7797\n",
            "Epoch 148/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3582 - categorical_accuracy: 0.8669 - val_loss: 0.5826 - val_categorical_accuracy: 0.7797\n",
            "Epoch 149/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4200 - categorical_accuracy: 0.8276 - val_loss: 0.5846 - val_categorical_accuracy: 0.7753\n",
            "Epoch 150/150\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.4646 - categorical_accuracy: 0.8019 - val_loss: 0.5822 - val_categorical_accuracy: 0.7753\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}